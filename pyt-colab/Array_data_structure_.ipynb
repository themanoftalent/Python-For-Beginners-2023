{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Array data structure .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmvukRocoUv1+/GVc/qMop",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/themanoftalent/pyt-colab/blob/master/Array_data_structure_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHdCNQJ4MLtD"
      },
      "source": [
        "bjective\n",
        "Today, we will learn about the Array data structure. Check out the Tutorial tab for learning materials and an instructional video.\n",
        "\n",
        "Task\n",
        "Given an array, , of  integers, print 's elements in reverse order as a single line of space-separated numbers.\n",
        "\n",
        "Example\n",
        "\n",
        "\n",
        "Print 4 3 2 1. Each integer is separated by one space.\n",
        "\n",
        "Input Format\n",
        "\n",
        "The first line contains an integer,  (the size of our array).\n",
        "The second line contains  space-separated integers that describe array 's elements.\n",
        "\n",
        "Constraints\n",
        "\n",
        "Constraints\n",
        "\n",
        ", where  is the  integer in the array.\n",
        "Output Format\n",
        "\n",
        "Print the elements of array  in reverse order as a single line of space-separated numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouvfCk6xGs0H",
        "outputId": "fd29523f-80d0-42ad-b2f9-db596af24b9a"
      },
      "source": [
        "#!/bin/python3\n",
        "\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import sys\n",
        "\n",
        "\n",
        "n = int(input().strip())\n",
        "arr = [int(sayi) for sayi in input().strip().split(' ')]\n",
        "\n",
        "for i in range(len(arr)):\n",
        "    print(str(arr[-i-1]), end=\" \")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "4\n",
            "4 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwWlQR3UGtke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e6cb512-b887-4880-9a8d-ac942911ddbf"
      },
      "source": [
        "sentence ='''The first line contains an integer, (the size of our array). The second 5 line contains space-separated integers that describe array 's elements. '''\n",
        "\n",
        "pattern='\\d'\n",
        "\n",
        "\n",
        "\n",
        "for i in re.finditer(pattern, sentence):\n",
        "  print('Bulunan sayi {0} ve yeri {1}'.format(i.group()[0],i.span()))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bulunan sayi 5 ve yeri (72, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I7iFd01Mreu"
      },
      "source": [
        "#remove stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNGDr3jtNa90",
        "outputId": "a9282d38-a130-407b-dc83-c10678ebf708"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1G4EosmPfLe"
      },
      "source": [
        "txt=''' Advancements in next-generation sequencer platforms have improved for NGS from sequence data \n",
        "production and reduced the cost involved, which has resulted in the production of a large amount of genome data. \n",
        "The downstream analysis of multiple associated sequences has become a bottleneck for the growing genomic data due to \n",
        "storage and space utilization issues in the domain of bioinformatics. off The traditional string-matching algorithms are efficient \n",
        "for small sized data sequences and cannot process large amounts of data for downstream for analysis. '''"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxOEtNm_Njxw"
      },
      "source": [
        "tokenles = word_tokenize(txt)\n",
        "wordes = stopwords.words()\n",
        "sent_tokens = sent_tokenize(txt)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFCu1PRYObYi"
      },
      "source": [
        "\n",
        "for wrd in tokenles:\n",
        "  if wrd not in wordes:\n",
        "    print(wrd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeWvjgM5OmmP",
        "outputId": "16b0c5bf-a032-49f5-ce22-e912fa49bdfb"
      },
      "source": [
        "for wordsss in sent_tokens:\n",
        "  if wordsss not in wordes:\n",
        "    print(wordsss)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Advancements in next-generation sequencer platforms have improved NGS sequence data \n",
            "production and reduced the cost involved, which has resulted in the production of a large amount of genome data.\n",
            "The downstream analysis of multiple associated sequences has become a bottleneck for the growing genomic data due to \n",
            "storage and space utilization issues in the domain of bioinformatics.\n",
            "off The traditional string-matching algorithms are efficient \n",
            "for small sized data sequences and cannot process large amounts of data for downstream for analysis.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1zuxMe4QwNO",
        "outputId": "4f2ca62a-14c3-4193-8610-40d74ad9c836"
      },
      "source": [
        "a=stopwords.words('english')\n",
        "print(a)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdnj3C0_RH33"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}